# ğŸ§  Named Entity Recognition (NER)

This project focuses on optimizing a natural language processing (NLP) pipeline to detect and classify named entities in **French texts**, across the following categories:

* `PER` â€“ Person
* `LOC` â€“ Location
* `ORG` â€“ Organization
* `MISC` â€“ Miscellaneous

We leverage **multiple NER tools** to maximize accuracy:

* **CasEN**: A linguistic rule-based system based on **Unitex**, developed by linguists.
* **spaCy**: A fast and efficient NLP library.
* **Stanza**: A deep learning-based NLP library from Stanford, well-suited for morphologically rich languages.

---

### ğŸ“ Single vs. Multiple Corpus Processing

We implemented an option that lets you choose whether to generate **one file per description** or a **single file for all descriptions combined**.

To preserve the traceability of each description's origin, we wrap them with custom tags in the merged file:

```xml
<doc id="X">
    [description content]
</doc>
```

This allows the system to:

- âœ… Significantly reduce execution time (more than 2Ã— faster in our tests)

- âœ… Better exploit generic graph-based rules, which can tag all similar entities once one is found

ğŸ“Š Entity Detection Results

| Mode                     | Total Entities Found | Gain    |
| ------------------------ | -------------------- | ------- |
| One file per description | 9,446                | â€”       |
| One file for all         | 13,233               | +40.09% |


---

## ğŸš€ CasEN Optimization

We then evaluated the **precision** and **entity yield** of each graph individually.

This analysis helped us identify certain graphsâ€”or combinations of graphsâ€”that provided the most benefit. We leveraged this insight to **prioritize and retain their extracted entities**, even if they were not detected by other systems.

### ğŸ” Example of a Graph Sequence

| Step            | Graph Name               |
|------------------|--------------------------|
| main_graph      | `grfpersCivilitePersonne` |
| second_graph  | `grftagCiviliteS`         |
| third_graph   | `grftagNomFamille`        |

These optimized sequences allow us to improve both recall and consistency across descriptions by capturing entities that would otherwise be missed.


---
## ğŸ”„ Multi-Model Entity Detection & Cross-Validation

Each text description is first processed individually by all three systems (**CasEN**, **spaCy**, and **Stanza**).
Then, we apply a **cross-validation strategy** during result fusion:

### ğŸ§¹ Cross-System Agreement

* If multiple systems detect the **same entity**, we merge their outputs and label them accordingly.
* Example: If both **CasEN** and **Stanza** detect "Nora" as a `PER`, the merged method becomes `CasEN_Stanza`.

### âš–ï¸ Conflict Resolution with Priority Rules

When an entity is detected by **multiple systems with different labels**, we apply **priority rules**:

* Entities found by **more systems** are considered more reliable.
* If systems agree on the **entity** but not on the **label**, we prioritize the **most frequent or reliable label** among agreeing systems.

#### ğŸ§  Example

![Excel Result Preview](src/images/image.png)

As shown above:

* Both **CasEN** and **Stanza** classify **â€œNoraâ€** as a **Person (`PER`)**.
* **spaCy**, however, classifies it as a **Location (`LOC`)**.

ğŸ“Œ As a result, the merged label becomes:

```txt
CasEN_Stanza_priority
```

This indicates that CasEN and Stanza agreed on both the entity and the label, and their interpretation takes precedence over spaCyâ€™s.

---
## ğŸ“Š Named Entity Recognition (NER) â€“ Evaluation Results

This section presents the evolution of NER performance across different configurations using **CasEN**, **SpaCy**, **Stanza**, and optimized graph sequences.



### ğŸ§ª Initial Evaluation (CasEN âˆ© SpaCy)

Entities detected using the intersection of CasEN and SpaCy systems at the beginning of the pipeline.
```bash
| Category | Total Entities | Accuracy |
|----------|----------------|----------|
| NE       | 4,085          | 97.67%   |
| PER      | 2,744          | 98.69%   |
| LOC      | 1,212          | 98.68%   |
| ORG      | 129            | 66.67%   |
| MISC     | 0              | 0.00%    |

```

### ğŸ“ CasEN on Single Corpus File (CasEN âˆ© SpaCy)

Performance after switching to a **single concatenated file** approach for CasEN.
```bash
| Category | Total Entities | Accuracy | Entity Gain | Accuracy Loss |
|----------|----------------|----------|--------------|----------------|
| NE       | 5,327          | âœ… 97.61%   | ğŸ”¼ +30.40%     | ğŸ”½ -0.06%         |
| PER      | 4,236          | âœ… 98.31%   | ğŸ”¼ +51.37%     | ğŸ”½ -0.37%         |
| LOC      | 952            | âœ… 98.83%   | ğŸ”½ -21.45%     | ğŸ”¼ +0.15%         |
| ORG      | 139            | âš ï¸ 66.92%   | ğŸ”¼ +7.75%      | ğŸ”½ -0.26%         |
| MISC     | 0              | âŒ 0.00%    | â– 0.00%       | â– 0.00%          |

```

### ğŸš€ CasEN + Optimized Graphs

Results using **CasEN with graph optimization** strategies.
```bash
| Category | Total Entities | Accuracy | Entity Gain | Accuracy Loss |
|----------|----------------|----------|--------------|----------------|
| NE       | 6,010          | âœ… 97.14%   | ğŸ”¼ +12.82%     | ğŸ”½ -0.47%         |
| PER      | 4,491          | âœ… 98.00%   | ğŸ”¼ +6.02%      | ğŸ”½ -0.31%         |
| LOC      | 1,294          | âœ… 97.78%   | ğŸ”¼ +35.92%     | ğŸ”¼ +1.05%         |
| ORG      | 225            | âš ï¸ 75.12%   | ğŸ”¼ +61.87%     | ğŸ”½ -8.20%         |
| MISC     | 0              | âŒ 0.00%    | â– 0.00%       | â– 0.00%          |

```

### ğŸ§  Full System: CasEN + SpaCy + Stanza + Optimization & Priority Rules

Final performance combining **all systems** with **graph priority strategies** and **CasEN optimizations**.
```bash
| Category | Total Entities | Accuracy | Entity Gain | Accuracy Loss |
|----------|----------------|----------|--------------|----------------|
| NE       | 7,086          | âœ… 97.08%   | ğŸ”¼ +17.90%     | ğŸ”½ -0.06%         |
| PER      | 5,592          | âœ… 97.37%   | ğŸ”¼ +24.52%     | ğŸ”½ -0.63%         |
| LOC      | 1,267          | âœ… 98.30%   | ğŸ”½ -2.09%      | ğŸ”¼ +0.52%         |
| ORG      | 227            | âš ï¸ 82.84%   | ğŸ”¼ +0.89%      | ğŸ”½ -7.72%         |
| MISC     | 0              | âŒ 0.00%    | â– 0.00%       | â– 0.00%          |
```


#### âœ… Summary

```bash
| Category | Total Entities | Accuracy | Entity Gain | Accuracy Loss |
|----------|----------------|----------|--------------|----------------|
| NE       | 7,086          | âœ…97.08%   | ğŸ”¼ +73.46%     | ğŸ”½ -0.60%         |
| PER      | 5,592          | âœ…97.37%   | ğŸ”¼ +103.79%     | ğŸ”½ -1.31%        |
| LOC      | 1,267          | âœ…98.30%   | ğŸ”¼ +4.54%      | ğŸ”½ -0.38%         |
| ORG      | 227            | âš ï¸ 82.84%   | ğŸ”¼ +75.97%      | ğŸ”¼ +16.18%         |
| MISC     | 0              | âŒ 0.00%    | â– 0.00%       | â– 0.00%          |
```


---
## ğŸ“… Installation

### 1. Clone the repository

```bash
git clone https://github.com/Valentin-Gauthier/NER.git
cd NER
```

### 2. Install dependencies

```bash
pip install -r requirements.txt
```

---

## âœï¸ Author

Valentin â€” Bachelorâ€™s degree, 3rd year, Computer Science
Internship at LIFAT - 2025
